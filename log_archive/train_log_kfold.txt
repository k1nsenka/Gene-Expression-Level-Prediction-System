calling dataloader ...
fold0 start
fold: 1/6 epoch: 1/200 train_loss: 0.456592 valid_loss: 0.402401
save model
fold: 1/6 epoch: 2/200 train_loss: 0.395984 valid_loss: 0.375159
save model
fold: 1/6 epoch: 3/200 train_loss: 0.323930 valid_loss: 0.283593
save model
fold: 1/6 epoch: 4/200 train_loss: 0.264581 valid_loss: 0.252181
save model
fold: 1/6 epoch: 5/200 train_loss: 0.245422 valid_loss: 0.242407
save model
fold: 1/6 epoch: 6/200 train_loss: 0.232067 valid_loss: 0.226283
save model
fold: 1/6 epoch: 7/200 train_loss: 0.223692 valid_loss: 0.220310
save model
fold: 1/6 epoch: 8/200 train_loss: 0.216566 valid_loss: 0.205622
save model
fold: 1/6 epoch: 9/200 train_loss: 0.205990 valid_loss: 0.199307
save model
fold: 1/6 epoch: 10/200 train_loss: 0.194891 valid_loss: 0.188261
save model
fold: 1/6 epoch: 11/200 train_loss: 0.179441 valid_loss: 0.163267
save model
fold: 1/6 epoch: 12/200 train_loss: 0.164087 valid_loss: 0.157406
save model
fold: 1/6 epoch: 13/200 train_loss: 0.156434 valid_loss: 0.164401
fold: 1/6 epoch: 14/200 train_loss: 0.153391 valid_loss: 0.144543
save model
fold: 1/6 epoch: 15/200 train_loss: 0.146003 valid_loss: 0.138724
save model
fold: 1/6 epoch: 16/200 train_loss: 0.144714 valid_loss: 0.134295
save model
fold: 1/6 epoch: 17/200 train_loss: 0.140649 valid_loss: 0.149713
fold: 1/6 epoch: 18/200 train_loss: 0.137926 valid_loss: 0.131494
save model
fold: 1/6 epoch: 19/200 train_loss: 0.136378 valid_loss: 0.126665
save model
fold: 1/6 epoch: 20/200 train_loss: 0.133213 valid_loss: 0.132424
fold: 1/6 epoch: 21/200 train_loss: 0.130598 valid_loss: 0.120947
save model
fold: 1/6 epoch: 22/200 train_loss: 0.128605 valid_loss: 0.127080
fold: 1/6 epoch: 23/200 train_loss: 0.125395 valid_loss: 0.135334
fold: 1/6 epoch: 24/200 train_loss: 0.125820 valid_loss: 0.123347
fold: 1/6 epoch: 25/200 train_loss: 0.124401 valid_loss: 0.130657
fold: 1/6 epoch: 26/200 train_loss: 0.123374 valid_loss: 0.115878
save model
fold: 1/6 epoch: 27/200 train_loss: 0.119328 valid_loss: 0.118437
fold: 1/6 epoch: 28/200 train_loss: 0.119619 valid_loss: 0.136916
fold: 1/6 epoch: 29/200 train_loss: 0.118421 valid_loss: 0.114353
save model
fold: 1/6 epoch: 30/200 train_loss: 0.117002 valid_loss: 0.117130
fold: 1/6 epoch: 31/200 train_loss: 0.116193 valid_loss: 0.108380
save model
fold: 1/6 epoch: 32/200 train_loss: 0.116057 valid_loss: 0.115171
fold: 1/6 epoch: 33/200 train_loss: 0.114135 valid_loss: 0.107896
save model
fold: 1/6 epoch: 34/200 train_loss: 0.111994 valid_loss: 0.109937
fold: 1/6 epoch: 35/200 train_loss: 0.110105 valid_loss: 0.109350
fold: 1/6 epoch: 36/200 train_loss: 0.110532 valid_loss: 0.107155
save model
fold: 1/6 epoch: 37/200 train_loss: 0.108843 valid_loss: 0.107800
fold: 1/6 epoch: 38/200 train_loss: 0.104903 valid_loss: 0.098193
save model
fold: 1/6 epoch: 39/200 train_loss: 0.102993 valid_loss: 0.102109
fold: 1/6 epoch: 40/200 train_loss: 0.101423 valid_loss: 0.112644
fold: 1/6 epoch: 41/200 train_loss: 0.099473 valid_loss: 0.096859
save model
fold: 1/6 epoch: 42/200 train_loss: 0.097331 valid_loss: 0.094310
save model
fold: 1/6 epoch: 43/200 train_loss: 0.095180 valid_loss: 0.089665
save model
fold: 1/6 epoch: 44/200 train_loss: 0.095116 valid_loss: 0.091671
fold: 1/6 epoch: 45/200 train_loss: 0.091795 valid_loss: 0.090435
fold: 1/6 epoch: 46/200 train_loss: 0.092929 valid_loss: 0.091247
fold: 1/6 epoch: 47/200 train_loss: 0.092540 valid_loss: 0.090964
fold: 1/6 epoch: 48/200 train_loss: 0.090515 valid_loss: 0.089307
save model
fold: 1/6 epoch: 49/200 train_loss: 0.088837 valid_loss: 0.089941
fold: 1/6 epoch: 50/200 train_loss: 0.090375 valid_loss: 0.088108
save model
fold: 1/6 epoch: 51/200 train_loss: 0.087103 valid_loss: 0.088000
save model
fold: 1/6 epoch: 52/200 train_loss: 0.086282 valid_loss: 0.087273
save model
fold: 1/6 epoch: 53/200 train_loss: 0.091048 valid_loss: 0.087881
fold: 1/6 epoch: 54/200 train_loss: 0.087297 valid_loss: 0.086467
save model
fold: 1/6 epoch: 55/200 train_loss: 0.087053 valid_loss: 0.086077
save model
fold: 1/6 epoch: 56/200 train_loss: 0.085763 valid_loss: 0.086270
fold: 1/6 epoch: 57/200 train_loss: 0.084220 valid_loss: 0.083463
save model
fold: 1/6 epoch: 58/200 train_loss: 0.082452 valid_loss: 0.085495
fold: 1/6 epoch: 59/200 train_loss: 0.081755 valid_loss: 0.085931
fold: 1/6 epoch: 60/200 train_loss: 0.082582 valid_loss: 0.086089
fold: 1/6 epoch: 61/200 train_loss: 0.080689 valid_loss: 0.084903
fold: 1/6 epoch: 62/200 train_loss: 0.081650 valid_loss: 0.083812
fold: 1/6 epoch: 63/200 train_loss: 0.080841 valid_loss: 0.082520
save model
fold: 1/6 epoch: 64/200 train_loss: 0.079784 valid_loss: 0.081625
save model
fold: 1/6 epoch: 65/200 train_loss: 0.078618 valid_loss: 0.082191
fold: 1/6 epoch: 66/200 train_loss: 0.077918 valid_loss: 0.081711
fold: 1/6 epoch: 67/200 train_loss: 0.077794 valid_loss: 0.079128
save model
fold: 1/6 epoch: 68/200 train_loss: 0.078774 valid_loss: 0.081130
fold: 1/6 epoch: 69/200 train_loss: 0.076508 valid_loss: 0.086953
fold: 1/6 epoch: 70/200 train_loss: 0.076382 valid_loss: 0.081175
fold: 1/6 epoch: 71/200 train_loss: 0.075662 valid_loss: 0.078575
save model
fold: 1/6 epoch: 72/200 train_loss: 0.074935 valid_loss: 0.078934
fold: 1/6 epoch: 73/200 train_loss: 0.075010 valid_loss: 0.077900
save model
fold: 1/6 epoch: 74/200 train_loss: 0.073567 valid_loss: 0.087303
fold: 1/6 epoch: 75/200 train_loss: 0.074291 valid_loss: 0.082561
fold: 1/6 epoch: 76/200 train_loss: 0.073568 valid_loss: 0.076650
save model
fold: 1/6 epoch: 77/200 train_loss: 0.072304 valid_loss: 0.080186
fold: 1/6 epoch: 78/200 train_loss: 0.071832 valid_loss: 0.084213
fold: 1/6 epoch: 79/200 train_loss: 0.070831 valid_loss: 0.081357
fold: 1/6 epoch: 80/200 train_loss: 0.070818 valid_loss: 0.077598
fold: 1/6 epoch: 81/200 train_loss: 0.069495 valid_loss: 0.075873
save model
fold: 1/6 epoch: 82/200 train_loss: 0.068756 valid_loss: 0.077515
fold: 1/6 epoch: 83/200 train_loss: 0.069135 valid_loss: 0.074592
save model
fold: 1/6 epoch: 84/200 train_loss: 0.067361 valid_loss: 0.081185
fold: 1/6 epoch: 85/200 train_loss: 0.066074 valid_loss: 0.074128
save model
fold: 1/6 epoch: 86/200 train_loss: 0.068640 valid_loss: 0.079809
fold: 1/6 epoch: 87/200 train_loss: 0.067392 valid_loss: 0.075079
fold: 1/6 epoch: 88/200 train_loss: 0.064971 valid_loss: 0.073350
save model
fold: 1/6 epoch: 89/200 train_loss: 0.066719 valid_loss: 0.072944
save model
fold: 1/6 epoch: 90/200 train_loss: 0.064742 valid_loss: 0.073990
fold: 1/6 epoch: 91/200 train_loss: 0.064206 valid_loss: 0.075372
fold: 1/6 epoch: 92/200 train_loss: 0.064216 valid_loss: 0.072623
save model
fold: 1/6 epoch: 93/200 train_loss: 0.062657 valid_loss: 0.075984
fold: 1/6 epoch: 94/200 train_loss: 0.064243 valid_loss: 0.074158
fold: 1/6 epoch: 95/200 train_loss: 0.063861 valid_loss: 0.076478
fold: 1/6 epoch: 96/200 train_loss: 0.061796 valid_loss: 0.075063
fold: 1/6 epoch: 97/200 train_loss: 0.060409 valid_loss: 0.071032
save model
fold: 1/6 epoch: 98/200 train_loss: 0.061094 valid_loss: 0.075507
fold: 1/6 epoch: 99/200 train_loss: 0.060090 valid_loss: 0.072174
fold: 1/6 epoch: 100/200 train_loss: 0.060290 valid_loss: 0.075569
fold: 1/6 epoch: 101/200 train_loss: 0.059633 valid_loss: 0.087743
fold: 1/6 epoch: 102/200 train_loss: 0.059055 valid_loss: 0.071610
fold: 1/6 epoch: 103/200 train_loss: 0.060423 valid_loss: 0.071644
fold: 1/6 epoch: 104/200 train_loss: 0.057814 valid_loss: 0.070366
save model
fold: 1/6 epoch: 105/200 train_loss: 0.055898 valid_loss: 0.073374
fold: 1/6 epoch: 106/200 train_loss: 0.057592 valid_loss: 0.077508
fold: 1/6 epoch: 107/200 train_loss: 0.064521 valid_loss: 0.072662
fold: 1/6 epoch: 108/200 train_loss: 0.056481 valid_loss: 0.074305
fold: 1/6 epoch: 109/200 train_loss: 0.055679 valid_loss: 0.070968
fold: 1/6 epoch: 110/200 train_loss: 0.055229 valid_loss: 0.072249
fold: 1/6 epoch: 111/200 train_loss: 0.055895 valid_loss: 0.072177
Early stopping
fold0, graph ploted
fold1 start
fold: 2/6 epoch: 1/200 train_loss: 0.440431 valid_loss: 0.399218
save model
fold: 2/6 epoch: 2/200 train_loss: 0.352945 valid_loss: 0.295056
save model
fold: 2/6 epoch: 3/200 train_loss: 0.270175 valid_loss: 0.254067
save model
fold: 2/6 epoch: 4/200 train_loss: 0.243537 valid_loss: 0.236113
save model
fold: 2/6 epoch: 5/200 train_loss: 0.230643 valid_loss: 0.220543
save model
fold: 2/6 epoch: 6/200 train_loss: 0.221837 valid_loss: 0.208719
save model
fold: 2/6 epoch: 7/200 train_loss: 0.212585 valid_loss: 0.202813
save model
fold: 2/6 epoch: 8/200 train_loss: 0.200035 valid_loss: 0.194775
save model
fold: 2/6 epoch: 9/200 train_loss: 0.188175 valid_loss: 0.171008
save model
fold: 2/6 epoch: 10/200 train_loss: 0.167167 valid_loss: 0.148300
save model
fold: 2/6 epoch: 11/200 train_loss: 0.159934 valid_loss: 0.199250
fold: 2/6 epoch: 12/200 train_loss: 0.160065 valid_loss: 0.155341
fold: 2/6 epoch: 13/200 train_loss: 0.151183 valid_loss: 0.135029
save model
fold: 2/6 epoch: 14/200 train_loss: 0.145172 valid_loss: 0.134037
save model
fold: 2/6 epoch: 15/200 train_loss: 0.143163 valid_loss: 0.129639
save model
fold: 2/6 epoch: 16/200 train_loss: 0.139114 valid_loss: 0.126792
save model
fold: 2/6 epoch: 17/200 train_loss: 0.137054 valid_loss: 0.135951
fold: 2/6 epoch: 18/200 train_loss: 0.136313 valid_loss: 0.120360
save model
fold: 2/6 epoch: 19/200 train_loss: 0.133619 valid_loss: 0.129601
fold: 2/6 epoch: 20/200 train_loss: 0.129064 valid_loss: 0.117512
save model
fold: 2/6 epoch: 21/200 train_loss: 0.129489 valid_loss: 0.119523
fold: 2/6 epoch: 22/200 train_loss: 0.125800 valid_loss: 0.116402
save model
fold: 2/6 epoch: 23/200 train_loss: 0.124140 valid_loss: 0.110368
save model
fold: 2/6 epoch: 24/200 train_loss: 0.123464 valid_loss: 0.112749
fold: 2/6 epoch: 25/200 train_loss: 0.121008 valid_loss: 0.110190
save model
fold: 2/6 epoch: 26/200 train_loss: 0.122108 valid_loss: 0.109452
save model
fold: 2/6 epoch: 27/200 train_loss: 0.119396 valid_loss: 0.107819
save model
fold: 2/6 epoch: 28/200 train_loss: 0.117037 valid_loss: 0.104026
save model
fold: 2/6 epoch: 29/200 train_loss: 0.118195 valid_loss: 0.104219
fold: 2/6 epoch: 30/200 train_loss: 0.116656 valid_loss: 0.104082
fold: 2/6 epoch: 31/200 train_loss: 0.114329 valid_loss: 0.100454
save model
fold: 2/6 epoch: 32/200 train_loss: 0.113734 valid_loss: 0.111863
fold: 2/6 epoch: 33/200 train_loss: 0.113421 valid_loss: 0.122910
fold: 2/6 epoch: 34/200 train_loss: 0.112443 valid_loss: 0.104003
fold: 2/6 epoch: 35/200 train_loss: 0.110457 valid_loss: 0.100851
fold: 2/6 epoch: 36/200 train_loss: 0.109890 valid_loss: 0.109538
fold: 2/6 epoch: 37/200 train_loss: 0.108125 valid_loss: 0.102905
fold: 2/6 epoch: 38/200 train_loss: 0.109781 valid_loss: 0.100165
save model
fold: 2/6 epoch: 39/200 train_loss: 0.104271 valid_loss: 0.090381
save model
fold: 2/6 epoch: 40/200 train_loss: 0.104876 valid_loss: 0.092843
fold: 2/6 epoch: 41/200 train_loss: 0.100044 valid_loss: 0.090630
fold: 2/6 epoch: 42/200 train_loss: 0.098602 valid_loss: 0.086269
save model
fold: 2/6 epoch: 43/200 train_loss: 0.099560 valid_loss: 0.088084
fold: 2/6 epoch: 44/200 train_loss: 0.094635 valid_loss: 0.083979
save model
fold: 2/6 epoch: 45/200 train_loss: 0.093925 valid_loss: 0.089484
fold: 2/6 epoch: 46/200 train_loss: 0.094465 valid_loss: 0.085660
fold: 2/6 epoch: 47/200 train_loss: 0.092492 valid_loss: 0.089216
fold: 2/6 epoch: 48/200 train_loss: 0.091272 valid_loss: 0.081843
save model
fold: 2/6 epoch: 49/200 train_loss: 0.090332 valid_loss: 0.085218
fold: 2/6 epoch: 50/200 train_loss: 0.089193 valid_loss: 0.078810
save model
fold: 2/6 epoch: 51/200 train_loss: 0.089172 valid_loss: 0.083559
fold: 2/6 epoch: 52/200 train_loss: 0.102831 valid_loss: 0.082732
fold: 2/6 epoch: 53/200 train_loss: 0.090257 valid_loss: 0.079247
fold: 2/6 epoch: 54/200 train_loss: 0.087871 valid_loss: 0.076578
save model
fold: 2/6 epoch: 55/200 train_loss: 0.086077 valid_loss: 0.085690
fold: 2/6 epoch: 56/200 train_loss: 0.086396 valid_loss: 0.076120
save model
fold: 2/6 epoch: 57/200 train_loss: 0.085563 valid_loss: 0.077456
fold: 2/6 epoch: 58/200 train_loss: 0.084620 valid_loss: 0.085521
fold: 2/6 epoch: 59/200 train_loss: 0.082621 valid_loss: 0.075936
save model
fold: 2/6 epoch: 60/200 train_loss: 0.084241 valid_loss: 0.075187
save model
fold: 2/6 epoch: 61/200 train_loss: 0.082883 valid_loss: 0.073178
save model
fold: 2/6 epoch: 62/200 train_loss: 0.081278 valid_loss: 0.084124
fold: 2/6 epoch: 63/200 train_loss: 0.081921 valid_loss: 0.075989
fold: 2/6 epoch: 64/200 train_loss: 0.080505 valid_loss: 0.073844
fold: 2/6 epoch: 65/200 train_loss: 0.080971 valid_loss: 0.073712
fold: 2/6 epoch: 66/200 train_loss: 0.080420 valid_loss: 0.075195
fold: 2/6 epoch: 67/200 train_loss: 0.079402 valid_loss: 0.070866
save model
fold: 2/6 epoch: 68/200 train_loss: 0.078574 valid_loss: 0.073584
fold: 2/6 epoch: 69/200 train_loss: 0.078072 valid_loss: 0.082665
fold: 2/6 epoch: 70/200 train_loss: 0.078187 valid_loss: 0.077276
fold: 2/6 epoch: 71/200 train_loss: 0.078199 valid_loss: 0.073949
fold: 2/6 epoch: 72/200 train_loss: 0.076232 valid_loss: 0.077514
fold: 2/6 epoch: 73/200 train_loss: 0.076243 valid_loss: 0.071889
fold: 2/6 epoch: 74/200 train_loss: 0.076165 valid_loss: 0.072379
Early stopping
fold1, graph ploted
fold2 start
fold: 3/6 epoch: 1/200 train_loss: 0.446450 valid_loss: 0.399609
save model
fold: 3/6 epoch: 2/200 train_loss: 0.380926 valid_loss: 0.331310
save model
fold: 3/6 epoch: 3/200 train_loss: 0.290627 valid_loss: 0.266627
save model
fold: 3/6 epoch: 4/200 train_loss: 0.281126 valid_loss: 0.266459
save model
fold: 3/6 epoch: 5/200 train_loss: 0.253280 valid_loss: 0.249995
save model
fold: 3/6 epoch: 6/200 train_loss: 0.238723 valid_loss: 0.242912
save model
fold: 3/6 epoch: 7/200 train_loss: 0.232454 valid_loss: 0.238143
save model
fold: 3/6 epoch: 8/200 train_loss: 0.227344 valid_loss: 0.238374
fold: 3/6 epoch: 9/200 train_loss: 0.223356 valid_loss: 0.224218
save model
fold: 3/6 epoch: 10/200 train_loss: 0.217284 valid_loss: 0.218448
save model
fold: 3/6 epoch: 11/200 train_loss: 0.210596 valid_loss: 0.220902
fold: 3/6 epoch: 12/200 train_loss: 0.205516 valid_loss: 0.217525
save model
fold: 3/6 epoch: 13/200 train_loss: 0.199735 valid_loss: 0.202984
save model
fold: 3/6 epoch: 14/200 train_loss: 0.190952 valid_loss: 0.198573
save model
fold: 3/6 epoch: 15/200 train_loss: 0.187616 valid_loss: 0.202268
fold: 3/6 epoch: 16/200 train_loss: 0.184362 valid_loss: 0.189171
save model
fold: 3/6 epoch: 17/200 train_loss: 0.179117 valid_loss: 0.193994
fold: 3/6 epoch: 18/200 train_loss: 0.176139 valid_loss: 0.183541
save model
fold: 3/6 epoch: 19/200 train_loss: 0.171733 valid_loss: 0.176862
save model
fold: 3/6 epoch: 20/200 train_loss: 0.170605 valid_loss: 0.178634
fold: 3/6 epoch: 21/200 train_loss: 0.165949 valid_loss: 0.177415
fold: 3/6 epoch: 22/200 train_loss: 0.163273 valid_loss: 0.170925
save model
fold: 3/6 epoch: 23/200 train_loss: 0.159953 valid_loss: 0.167650
save model
fold: 3/6 epoch: 24/200 train_loss: 0.156342 valid_loss: 0.161968
save model
fold: 3/6 epoch: 25/200 train_loss: 0.153931 valid_loss: 0.158983
save model
fold: 3/6 epoch: 26/200 train_loss: 0.148350 valid_loss: 0.157395
save model
fold: 3/6 epoch: 27/200 train_loss: 0.143816 valid_loss: 0.153127
save model
fold: 3/6 epoch: 28/200 train_loss: 0.140212 valid_loss: 0.151736
save model
fold: 3/6 epoch: 29/200 train_loss: 0.140227 valid_loss: 0.154845
fold: 3/6 epoch: 30/200 train_loss: 0.135534 valid_loss: 0.145311
save model
fold: 3/6 epoch: 31/200 train_loss: 0.133472 valid_loss: 0.146682
fold: 3/6 epoch: 32/200 train_loss: 0.130821 valid_loss: 0.144069
save model
fold: 3/6 epoch: 33/200 train_loss: 0.135999 valid_loss: 0.140098
save model
fold: 3/6 epoch: 34/200 train_loss: 0.127904 valid_loss: 0.141449
fold: 3/6 epoch: 35/200 train_loss: 0.125838 valid_loss: 0.139349
save model
fold: 3/6 epoch: 36/200 train_loss: 0.123986 valid_loss: 0.133927
save model
fold: 3/6 epoch: 37/200 train_loss: 0.124044 valid_loss: 0.138832
fold: 3/6 epoch: 38/200 train_loss: 0.122685 valid_loss: 0.166228
fold: 3/6 epoch: 39/200 train_loss: 0.120581 valid_loss: 0.133889
save model
fold: 3/6 epoch: 40/200 train_loss: 0.117045 valid_loss: 0.126130
save model
fold: 3/6 epoch: 41/200 train_loss: 0.113917 valid_loss: 0.135370
fold: 3/6 epoch: 42/200 train_loss: 0.111949 valid_loss: 0.126112
save model
fold: 3/6 epoch: 43/200 train_loss: 0.110356 valid_loss: 0.118937
save model
fold: 3/6 epoch: 44/200 train_loss: 0.107399 valid_loss: 0.124068
fold: 3/6 epoch: 45/200 train_loss: 0.105166 valid_loss: 0.114811
save model
fold: 3/6 epoch: 46/200 train_loss: 0.103318 valid_loss: 0.116050
fold: 3/6 epoch: 47/200 train_loss: 0.101513 valid_loss: 0.116430
fold: 3/6 epoch: 48/200 train_loss: 0.101810 valid_loss: 0.114313
save model
fold: 3/6 epoch: 49/200 train_loss: 0.101046 valid_loss: 0.114777
fold: 3/6 epoch: 50/200 train_loss: 0.097412 valid_loss: 0.110511
save model
fold: 3/6 epoch: 51/200 train_loss: 0.097828 valid_loss: 0.108950
save model
fold: 3/6 epoch: 52/200 train_loss: 0.095818 valid_loss: 0.111526
fold: 3/6 epoch: 53/200 train_loss: 0.095703 valid_loss: 0.109918
fold: 3/6 epoch: 54/200 train_loss: 0.094723 valid_loss: 0.113921
fold: 3/6 epoch: 55/200 train_loss: 0.093665 valid_loss: 0.109647
fold: 3/6 epoch: 56/200 train_loss: 0.092796 valid_loss: 0.109513
fold: 3/6 epoch: 57/200 train_loss: 0.093314 valid_loss: 0.108969
fold: 3/6 epoch: 58/200 train_loss: 0.092266 valid_loss: 0.109666
Early stopping
fold2, graph ploted
fold3 start
fold: 4/6 epoch: 1/200 train_loss: 0.450318 valid_loss: 0.399257
save model
fold: 4/6 epoch: 2/200 train_loss: 0.373567 valid_loss: 0.320079
save model
fold: 4/6 epoch: 3/200 train_loss: 0.291230 valid_loss: 0.263967
save model
fold: 4/6 epoch: 4/200 train_loss: 0.256475 valid_loss: 0.246286
save model
fold: 4/6 epoch: 5/200 train_loss: 0.238185 valid_loss: 0.229943
save model
fold: 4/6 epoch: 6/200 train_loss: 0.228492 valid_loss: 0.238519
fold: 4/6 epoch: 7/200 train_loss: 0.221526 valid_loss: 0.214088
save model
fold: 4/6 epoch: 8/200 train_loss: 0.211646 valid_loss: 0.207304
save model
fold: 4/6 epoch: 9/200 train_loss: 0.201107 valid_loss: 0.205572
save model
fold: 4/6 epoch: 10/200 train_loss: 0.188718 valid_loss: 0.186710
save model
fold: 4/6 epoch: 11/200 train_loss: 0.170441 valid_loss: 0.162715
save model
fold: 4/6 epoch: 12/200 train_loss: 0.160672 valid_loss: 0.158257
save model
fold: 4/6 epoch: 13/200 train_loss: 0.153991 valid_loss: 0.153623
save model
fold: 4/6 epoch: 14/200 train_loss: 0.149949 valid_loss: 0.155820
fold: 4/6 epoch: 15/200 train_loss: 0.145239 valid_loss: 0.141999
save model
fold: 4/6 epoch: 16/200 train_loss: 0.143315 valid_loss: 0.148942
fold: 4/6 epoch: 17/200 train_loss: 0.138667 valid_loss: 0.142459
fold: 4/6 epoch: 18/200 train_loss: 0.137416 valid_loss: 0.135188
save model
fold: 4/6 epoch: 19/200 train_loss: 0.134657 valid_loss: 0.136968
fold: 4/6 epoch: 20/200 train_loss: 0.133678 valid_loss: 0.133225
save model
fold: 4/6 epoch: 21/200 train_loss: 0.135138 valid_loss: 0.131856
save model
fold: 4/6 epoch: 22/200 train_loss: 0.127805 valid_loss: 0.129585
save model
fold: 4/6 epoch: 23/200 train_loss: 0.127954 valid_loss: 0.134556
fold: 4/6 epoch: 24/200 train_loss: 0.123611 valid_loss: 0.131211
fold: 4/6 epoch: 25/200 train_loss: 0.122458 valid_loss: 0.135922
fold: 4/6 epoch: 26/200 train_loss: 0.123404 valid_loss: 0.122194
save model
fold: 4/6 epoch: 27/200 train_loss: 0.118066 valid_loss: 0.118879
save model
fold: 4/6 epoch: 28/200 train_loss: 0.118291 valid_loss: 0.118387
save model
fold: 4/6 epoch: 29/200 train_loss: 0.115749 valid_loss: 0.125190
fold: 4/6 epoch: 30/200 train_loss: 0.111372 valid_loss: 0.116534
save model
fold: 4/6 epoch: 31/200 train_loss: 0.110111 valid_loss: 0.114813
save model
fold: 4/6 epoch: 32/200 train_loss: 0.106085 valid_loss: 0.112603
save model
fold: 4/6 epoch: 33/200 train_loss: 0.101037 valid_loss: 0.109285
save model
fold: 4/6 epoch: 34/200 train_loss: 0.100743 valid_loss: 0.104533
save model
fold: 4/6 epoch: 35/200 train_loss: 0.099681 valid_loss: 0.106864
fold: 4/6 epoch: 36/200 train_loss: 0.097514 valid_loss: 0.104205
save model
fold: 4/6 epoch: 37/200 train_loss: 0.097024 valid_loss: 0.116308
fold: 4/6 epoch: 38/200 train_loss: 0.096265 valid_loss: 0.103726
save model
fold: 4/6 epoch: 39/200 train_loss: 0.096819 valid_loss: 0.103323
save model
fold: 4/6 epoch: 40/200 train_loss: 0.095705 valid_loss: 0.101834
save model
fold: 4/6 epoch: 41/200 train_loss: 0.093753 valid_loss: 0.102985
fold: 4/6 epoch: 42/200 train_loss: 0.092670 valid_loss: 0.101898
fold: 4/6 epoch: 43/200 train_loss: 0.091107 valid_loss: 0.097409
save model
fold: 4/6 epoch: 44/200 train_loss: 0.090899 valid_loss: 0.107615
fold: 4/6 epoch: 45/200 train_loss: 0.089969 valid_loss: 0.098447
fold: 4/6 epoch: 46/200 train_loss: 0.088591 valid_loss: 0.096601
save model
fold: 4/6 epoch: 47/200 train_loss: 0.090112 valid_loss: 0.099119
fold: 4/6 epoch: 48/200 train_loss: 0.087224 valid_loss: 0.096666
fold: 4/6 epoch: 49/200 train_loss: 0.087143 valid_loss: 0.098570
fold: 4/6 epoch: 50/200 train_loss: 0.086490 valid_loss: 0.093175
save model
fold: 4/6 epoch: 51/200 train_loss: 0.086376 valid_loss: 0.095483
fold: 4/6 epoch: 52/200 train_loss: 0.084263 valid_loss: 0.093728
fold: 4/6 epoch: 53/200 train_loss: 0.085355 valid_loss: 0.093739
fold: 4/6 epoch: 54/200 train_loss: 0.082848 valid_loss: 0.092999
save model
fold: 4/6 epoch: 55/200 train_loss: 0.081859 valid_loss: 0.093942
fold: 4/6 epoch: 56/200 train_loss: 0.112249 valid_loss: 0.099088
fold: 4/6 epoch: 57/200 train_loss: 0.091139 valid_loss: 0.096795
fold: 4/6 epoch: 58/200 train_loss: 0.087148 valid_loss: 0.093161
fold: 4/6 epoch: 59/200 train_loss: 0.083917 valid_loss: 0.096318
fold: 4/6 epoch: 60/200 train_loss: 0.083327 valid_loss: 0.095363
fold: 4/6 epoch: 61/200 train_loss: 0.080811 valid_loss: 0.088424
save model
fold: 4/6 epoch: 62/200 train_loss: 0.080155 valid_loss: 0.090854
fold: 4/6 epoch: 63/200 train_loss: 0.078901 valid_loss: 0.094412
fold: 4/6 epoch: 64/200 train_loss: 0.079022 valid_loss: 0.087758
save model
fold: 4/6 epoch: 65/200 train_loss: 0.078460 valid_loss: 0.091335
fold: 4/6 epoch: 66/200 train_loss: 0.078700 valid_loss: 0.094143
fold: 4/6 epoch: 67/200 train_loss: 0.076780 valid_loss: 0.089277
fold: 4/6 epoch: 68/200 train_loss: 0.077355 valid_loss: 0.088439
fold: 4/6 epoch: 69/200 train_loss: 0.077510 valid_loss: 0.094473
fold: 4/6 epoch: 70/200 train_loss: 0.076044 valid_loss: 0.094604
fold: 4/6 epoch: 71/200 train_loss: 0.076286 valid_loss: 0.091077
Early stopping
fold3, graph ploted
fold4 start
fold: 5/6 epoch: 1/200 train_loss: 0.480935 valid_loss: 0.401699
save model
fold: 5/6 epoch: 2/200 train_loss: 0.398722 valid_loss: 0.397344
save model
fold: 5/6 epoch: 3/200 train_loss: 0.355055 valid_loss: 0.314510
save model
fold: 5/6 epoch: 4/200 train_loss: 0.282459 valid_loss: 0.257624
save model
fold: 5/6 epoch: 5/200 train_loss: 0.249896 valid_loss: 0.239970
save model
fold: 5/6 epoch: 6/200 train_loss: 0.235832 valid_loss: 0.231658
save model
fold: 5/6 epoch: 7/200 train_loss: 0.228279 valid_loss: 0.226655
save model
fold: 5/6 epoch: 8/200 train_loss: 0.220816 valid_loss: 0.217830
save model
fold: 5/6 epoch: 9/200 train_loss: 0.216424 valid_loss: 0.212507
save model
fold: 5/6 epoch: 10/200 train_loss: 0.207293 valid_loss: 0.200640
save model
fold: 5/6 epoch: 11/200 train_loss: 0.199164 valid_loss: 0.206525
fold: 5/6 epoch: 12/200 train_loss: 0.193278 valid_loss: 0.191115
save model
fold: 5/6 epoch: 13/200 train_loss: 0.185099 valid_loss: 0.179681
save model
fold: 5/6 epoch: 14/200 train_loss: 0.178723 valid_loss: 0.177443
save model
fold: 5/6 epoch: 15/200 train_loss: 0.166296 valid_loss: 0.156861
save model
fold: 5/6 epoch: 16/200 train_loss: 0.156726 valid_loss: 0.148631
save model
fold: 5/6 epoch: 17/200 train_loss: 0.148566 valid_loss: 0.143141
save model
fold: 5/6 epoch: 18/200 train_loss: 0.146054 valid_loss: 0.145726
fold: 5/6 epoch: 19/200 train_loss: 0.140343 valid_loss: 0.138791
save model
fold: 5/6 epoch: 20/200 train_loss: 0.137465 valid_loss: 0.135605
save model
fold: 5/6 epoch: 21/200 train_loss: 0.136160 valid_loss: 0.139762
fold: 5/6 epoch: 22/200 train_loss: 0.134196 valid_loss: 0.132438
save model
fold: 5/6 epoch: 23/200 train_loss: 0.131865 valid_loss: 0.128971
save model
fold: 5/6 epoch: 24/200 train_loss: 0.131193 valid_loss: 0.131217
fold: 5/6 epoch: 25/200 train_loss: 0.128222 valid_loss: 0.129207
fold: 5/6 epoch: 26/200 train_loss: 0.124960 valid_loss: 0.128707
save model
fold: 5/6 epoch: 27/200 train_loss: 0.124749 valid_loss: 0.121988
save model
fold: 5/6 epoch: 28/200 train_loss: 0.124669 valid_loss: 0.127792
fold: 5/6 epoch: 29/200 train_loss: 0.120414 valid_loss: 0.128184
fold: 5/6 epoch: 30/200 train_loss: 0.119496 valid_loss: 0.122634
fold: 5/6 epoch: 31/200 train_loss: 0.118085 valid_loss: 0.117399
save model
fold: 5/6 epoch: 32/200 train_loss: 0.117395 valid_loss: 0.117053
save model
fold: 5/6 epoch: 33/200 train_loss: 0.114184 valid_loss: 0.119490
fold: 5/6 epoch: 34/200 train_loss: 0.114695 valid_loss: 0.116275
save model
fold: 5/6 epoch: 35/200 train_loss: 0.111474 valid_loss: 0.116489
fold: 5/6 epoch: 36/200 train_loss: 0.110487 valid_loss: 0.110823
save model
fold: 5/6 epoch: 37/200 train_loss: 0.157337 valid_loss: 0.126789
fold: 5/6 epoch: 38/200 train_loss: 0.122132 valid_loss: 0.123164
fold: 5/6 epoch: 39/200 train_loss: 0.114150 valid_loss: 0.123958
fold: 5/6 epoch: 40/200 train_loss: 0.109684 valid_loss: 0.114318
fold: 5/6 epoch: 41/200 train_loss: 0.105924 valid_loss: 0.110762
save model
fold: 5/6 epoch: 42/200 train_loss: 0.102899 valid_loss: 0.107516
save model
fold: 5/6 epoch: 43/200 train_loss: 0.101813 valid_loss: 0.105230
save model
fold: 5/6 epoch: 44/200 train_loss: 0.098901 valid_loss: 0.103950
save model
fold: 5/6 epoch: 45/200 train_loss: 0.098772 valid_loss: 0.100307
save model
fold: 5/6 epoch: 46/200 train_loss: 0.097737 valid_loss: 0.111577
fold: 5/6 epoch: 47/200 train_loss: 0.096568 valid_loss: 0.099423
save model
fold: 5/6 epoch: 48/200 train_loss: 0.096657 valid_loss: 0.103508
fold: 5/6 epoch: 49/200 train_loss: 0.093514 valid_loss: 0.095572
save model
fold: 5/6 epoch: 50/200 train_loss: 0.093812 valid_loss: 0.096767
fold: 5/6 epoch: 51/200 train_loss: 0.092017 valid_loss: 0.099190
fold: 5/6 epoch: 52/200 train_loss: 0.091324 valid_loss: 0.101315
fold: 5/6 epoch: 53/200 train_loss: 0.089806 valid_loss: 0.094059
save model
fold: 5/6 epoch: 54/200 train_loss: 0.090075 valid_loss: 0.093170
save model
fold: 5/6 epoch: 55/200 train_loss: 0.089023 valid_loss: 0.093742
fold: 5/6 epoch: 56/200 train_loss: 0.087185 valid_loss: 0.094311
fold: 5/6 epoch: 57/200 train_loss: 0.087104 valid_loss: 0.092307
save model
fold: 5/6 epoch: 58/200 train_loss: 0.087540 valid_loss: 0.091825
save model
fold: 5/6 epoch: 59/200 train_loss: 0.086953 valid_loss: 0.093435
fold: 5/6 epoch: 60/200 train_loss: 0.084776 valid_loss: 0.092131
fold: 5/6 epoch: 61/200 train_loss: 0.086412 valid_loss: 0.096578
fold: 5/6 epoch: 62/200 train_loss: 0.085164 valid_loss: 0.093767
fold: 5/6 epoch: 63/200 train_loss: 0.082865 valid_loss: 0.090797
save model
fold: 5/6 epoch: 64/200 train_loss: 0.084086 valid_loss: 0.088364
save model
fold: 5/6 epoch: 65/200 train_loss: 0.082949 valid_loss: 0.089157
fold: 5/6 epoch: 66/200 train_loss: 0.080942 valid_loss: 0.091573
fold: 5/6 epoch: 67/200 train_loss: 0.080802 valid_loss: 0.087077
save model
fold: 5/6 epoch: 68/200 train_loss: 0.079130 valid_loss: 0.090554
fold: 5/6 epoch: 69/200 train_loss: 0.080712 valid_loss: 0.087842
fold: 5/6 epoch: 70/200 train_loss: 0.079187 valid_loss: 0.091622
fold: 5/6 epoch: 71/200 train_loss: 0.078707 valid_loss: 0.095697
fold: 5/6 epoch: 72/200 train_loss: 0.079370 valid_loss: 0.090322
fold: 5/6 epoch: 73/200 train_loss: 0.079608 valid_loss: 0.090830
fold: 5/6 epoch: 74/200 train_loss: 0.078764 valid_loss: 0.086712
save model
fold: 5/6 epoch: 75/200 train_loss: 0.076473 valid_loss: 0.090806
fold: 5/6 epoch: 76/200 train_loss: 0.074949 valid_loss: 0.087932
fold: 5/6 epoch: 77/200 train_loss: 0.077491 valid_loss: 0.085119
save model
fold: 5/6 epoch: 78/200 train_loss: 0.075348 valid_loss: 0.091050
fold: 5/6 epoch: 79/200 train_loss: 0.074169 valid_loss: 0.083985
save model
fold: 5/6 epoch: 80/200 train_loss: 0.074084 valid_loss: 0.085692
fold: 5/6 epoch: 81/200 train_loss: 0.073382 valid_loss: 0.084164
fold: 5/6 epoch: 82/200 train_loss: 0.073595 valid_loss: 0.087983
fold: 5/6 epoch: 83/200 train_loss: 0.072331 valid_loss: 0.092117
fold: 5/6 epoch: 84/200 train_loss: 0.072728 valid_loss: 0.092564
fold: 5/6 epoch: 85/200 train_loss: 0.072926 valid_loss: 0.083310
save model
fold: 5/6 epoch: 86/200 train_loss: 0.070405 valid_loss: 0.082935
save model
fold: 5/6 epoch: 87/200 train_loss: 0.069271 valid_loss: 0.086558
fold: 5/6 epoch: 88/200 train_loss: 0.069700 valid_loss: 0.085978
fold: 5/6 epoch: 89/200 train_loss: 0.068531 valid_loss: 0.083423
fold: 5/6 epoch: 90/200 train_loss: 0.068951 valid_loss: 0.084461
fold: 5/6 epoch: 91/200 train_loss: 0.068554 valid_loss: 0.084480
fold: 5/6 epoch: 92/200 train_loss: 0.068141 valid_loss: 0.082943
fold: 5/6 epoch: 93/200 train_loss: 0.067794 valid_loss: 0.081873
save model
fold: 5/6 epoch: 94/200 train_loss: 0.067859 valid_loss: 0.082438
fold: 5/6 epoch: 95/200 train_loss: 0.065997 valid_loss: 0.080030
save model
fold: 5/6 epoch: 96/200 train_loss: 0.066792 valid_loss: 0.084401
fold: 5/6 epoch: 97/200 train_loss: 0.064600 valid_loss: 0.087062
fold: 5/6 epoch: 98/200 train_loss: 0.064030 valid_loss: 0.087935
fold: 5/6 epoch: 99/200 train_loss: 0.063984 valid_loss: 0.080112
fold: 5/6 epoch: 100/200 train_loss: 0.063673 valid_loss: 0.092546
fold: 5/6 epoch: 101/200 train_loss: 0.064237 valid_loss: 0.080676
fold: 5/6 epoch: 102/200 train_loss: 0.063506 valid_loss: 0.082897
Early stopping
fold4, graph ploted
fold5 start
fold: 6/6 epoch: 1/200 train_loss: 0.442572 valid_loss: 0.396390
save model
fold: 6/6 epoch: 2/200 train_loss: 0.360801 valid_loss: 0.327034
save model
fold: 6/6 epoch: 3/200 train_loss: 0.278650 valid_loss: 0.257620
save model
fold: 6/6 epoch: 4/200 train_loss: 0.276278 valid_loss: 0.421607
fold: 6/6 epoch: 5/200 train_loss: 0.300863 valid_loss: 0.261080
fold: 6/6 epoch: 6/200 train_loss: 0.252871 valid_loss: 0.246146
save model
fold: 6/6 epoch: 7/200 train_loss: 0.241371 valid_loss: 0.237478
save model
fold: 6/6 epoch: 8/200 train_loss: 0.236176 valid_loss: 0.238341
fold: 6/6 epoch: 9/200 train_loss: 0.233418 valid_loss: 0.227371
save model
fold: 6/6 epoch: 10/200 train_loss: 0.228002 valid_loss: 0.225386
save model
fold: 6/6 epoch: 11/200 train_loss: 0.224989 valid_loss: 0.222697
save model
fold: 6/6 epoch: 12/200 train_loss: 0.221262 valid_loss: 0.216737
save model
fold: 6/6 epoch: 13/200 train_loss: 0.217227 valid_loss: 0.214186
save model
fold: 6/6 epoch: 14/200 train_loss: 0.214479 valid_loss: 0.212447
save model
fold: 6/6 epoch: 15/200 train_loss: 0.209172 valid_loss: 0.206754
save model
fold: 6/6 epoch: 16/200 train_loss: 0.203855 valid_loss: 0.197447
save model
fold: 6/6 epoch: 17/200 train_loss: 0.197437 valid_loss: 0.192533
save model
fold: 6/6 epoch: 18/200 train_loss: 0.193024 valid_loss: 0.194040
fold: 6/6 epoch: 19/200 train_loss: 0.189713 valid_loss: 0.185729
save model
fold: 6/6 epoch: 20/200 train_loss: 0.185797 valid_loss: 0.196487
fold: 6/6 epoch: 21/200 train_loss: 0.182089 valid_loss: 0.184885
save model
fold: 6/6 epoch: 22/200 train_loss: 0.175390 valid_loss: 0.168810
save model
fold: 6/6 epoch: 23/200 train_loss: 0.166520 valid_loss: 0.163431
save model
fold: 6/6 epoch: 24/200 train_loss: 0.162093 valid_loss: 0.161766
save model
fold: 6/6 epoch: 25/200 train_loss: 0.152519 valid_loss: 0.151609
save model
fold: 6/6 epoch: 26/200 train_loss: 0.153795 valid_loss: 0.150863
save model
fold: 6/6 epoch: 27/200 train_loss: 0.146770 valid_loss: 0.153521
fold: 6/6 epoch: 28/200 train_loss: 0.147761 valid_loss: 0.147157
save model
fold: 6/6 epoch: 29/200 train_loss: 0.140630 valid_loss: 0.140025
save model
fold: 6/6 epoch: 30/200 train_loss: 0.139298 valid_loss: 0.169500
fold: 6/6 epoch: 31/200 train_loss: 0.139002 valid_loss: 0.138377
save model
fold: 6/6 epoch: 32/200 train_loss: 0.139511 valid_loss: 0.137011
save model
fold: 6/6 epoch: 33/200 train_loss: 0.135511 valid_loss: 0.138585
fold: 6/6 epoch: 34/200 train_loss: 0.132284 valid_loss: 0.139068
fold: 6/6 epoch: 35/200 train_loss: 0.134411 valid_loss: 0.133140
save model
fold: 6/6 epoch: 36/200 train_loss: 0.129630 valid_loss: 0.135536
fold: 6/6 epoch: 37/200 train_loss: 0.130552 valid_loss: 0.134093
fold: 6/6 epoch: 38/200 train_loss: 0.127001 valid_loss: 0.127961
save model
fold: 6/6 epoch: 39/200 train_loss: 0.128163 valid_loss: 0.142412
fold: 6/6 epoch: 40/200 train_loss: 0.128896 valid_loss: 0.136263
fold: 6/6 epoch: 41/200 train_loss: 0.124245 valid_loss: 0.132163
fold: 6/6 epoch: 42/200 train_loss: 0.125158 valid_loss: 0.122789
save model
fold: 6/6 epoch: 43/200 train_loss: 0.121738 valid_loss: 0.130943
fold: 6/6 epoch: 44/200 train_loss: 0.123477 valid_loss: 0.133439
fold: 6/6 epoch: 45/200 train_loss: 0.121938 valid_loss: 0.178108
fold: 6/6 epoch: 46/200 train_loss: 0.122390 valid_loss: 0.124027
fold: 6/6 epoch: 47/200 train_loss: 0.119624 valid_loss: 0.121198
save model
fold: 6/6 epoch: 48/200 train_loss: 0.117915 valid_loss: 0.130087
fold: 6/6 epoch: 49/200 train_loss: 0.119123 valid_loss: 0.121197
save model
fold: 6/6 epoch: 50/200 train_loss: 0.116036 valid_loss: 0.120462
save model
fold: 6/6 epoch: 51/200 train_loss: 0.115435 valid_loss: 0.118931
save model
fold: 6/6 epoch: 52/200 train_loss: 0.113655 valid_loss: 0.116193
save model
fold: 6/6 epoch: 53/200 train_loss: 0.112871 valid_loss: 0.122035
fold: 6/6 epoch: 54/200 train_loss: 0.113457 valid_loss: 0.116764
fold: 6/6 epoch: 55/200 train_loss: 0.111432 valid_loss: 0.116754
fold: 6/6 epoch: 56/200 train_loss: 0.111454 valid_loss: 0.114764
save model
fold: 6/6 epoch: 57/200 train_loss: 0.109036 valid_loss: 0.116134
fold: 6/6 epoch: 58/200 train_loss: 0.109876 valid_loss: 0.114404
save model
fold: 6/6 epoch: 59/200 train_loss: 0.107926 valid_loss: 0.119032
fold: 6/6 epoch: 60/200 train_loss: 0.107412 valid_loss: 0.113435
save model
fold: 6/6 epoch: 61/200 train_loss: 0.108083 valid_loss: 0.119109
fold: 6/6 epoch: 62/200 train_loss: 0.106028 valid_loss: 0.109711
save model
fold: 6/6 epoch: 63/200 train_loss: 0.103832 valid_loss: 0.107545
save model
fold: 6/6 epoch: 64/200 train_loss: 0.103457 valid_loss: 0.104109
save model
fold: 6/6 epoch: 65/200 train_loss: 0.098851 valid_loss: 0.102133
save model
fold: 6/6 epoch: 66/200 train_loss: 0.098541 valid_loss: 0.103299
fold: 6/6 epoch: 67/200 train_loss: 0.096828 valid_loss: 0.103133
fold: 6/6 epoch: 68/200 train_loss: 0.094247 valid_loss: 0.099709
save model
fold: 6/6 epoch: 69/200 train_loss: 0.095616 valid_loss: 0.098821
save model
fold: 6/6 epoch: 70/200 train_loss: 0.091393 valid_loss: 0.095926
save model
fold: 6/6 epoch: 71/200 train_loss: 0.090472 valid_loss: 0.097111
fold: 6/6 epoch: 72/200 train_loss: 0.089087 valid_loss: 0.097483
fold: 6/6 epoch: 73/200 train_loss: 0.088354 valid_loss: 0.095498
save model
fold: 6/6 epoch: 74/200 train_loss: 0.086534 valid_loss: 0.093219
save model
fold: 6/6 epoch: 75/200 train_loss: 0.086665 valid_loss: 0.097121
fold: 6/6 epoch: 76/200 train_loss: 0.086481 valid_loss: 0.093153
save model
fold: 6/6 epoch: 77/200 train_loss: 0.084313 valid_loss: 0.093995
fold: 6/6 epoch: 78/200 train_loss: 0.083718 valid_loss: 0.093217
fold: 6/6 epoch: 79/200 train_loss: 0.083264 valid_loss: 0.095875
fold: 6/6 epoch: 80/200 train_loss: 0.083778 valid_loss: 0.096278
fold: 6/6 epoch: 81/200 train_loss: 0.082439 valid_loss: 0.096420
fold: 6/6 epoch: 82/200 train_loss: 0.081828 valid_loss: 0.095020
fold: 6/6 epoch: 83/200 train_loss: 0.081866 valid_loss: 0.091710
save model
fold: 6/6 epoch: 84/200 train_loss: 0.080350 valid_loss: 0.092471
fold: 6/6 epoch: 85/200 train_loss: 0.079106 valid_loss: 0.088785
save model
fold: 6/6 epoch: 86/200 train_loss: 0.080275 valid_loss: 0.089367
fold: 6/6 epoch: 87/200 train_loss: 0.079812 valid_loss: 0.093920
fold: 6/6 epoch: 88/200 train_loss: 0.079343 valid_loss: 0.093960
fold: 6/6 epoch: 89/200 train_loss: 0.076875 valid_loss: 0.093780
fold: 6/6 epoch: 90/200 train_loss: 0.077780 valid_loss: 0.092084
fold: 6/6 epoch: 91/200 train_loss: 0.076789 valid_loss: 0.088096
save model
fold: 6/6 epoch: 92/200 train_loss: 0.074933 valid_loss: 0.092109
fold: 6/6 epoch: 93/200 train_loss: 0.075215 valid_loss: 0.087606
save model
fold: 6/6 epoch: 94/200 train_loss: 0.075439 valid_loss: 0.088357
fold: 6/6 epoch: 95/200 train_loss: 0.073720 valid_loss: 0.093944
fold: 6/6 epoch: 96/200 train_loss: 0.074877 valid_loss: 0.088697
fold: 6/6 epoch: 97/200 train_loss: 0.073525 valid_loss: 0.086566
save model
fold: 6/6 epoch: 98/200 train_loss: 0.072905 valid_loss: 0.086968
fold: 6/6 epoch: 99/200 train_loss: 0.071480 valid_loss: 0.088930
fold: 6/6 epoch: 100/200 train_loss: 0.072678 valid_loss: 0.089762
fold: 6/6 epoch: 101/200 train_loss: 0.071356 valid_loss: 0.088309
fold: 6/6 epoch: 102/200 train_loss: 0.069273 valid_loss: 0.085640
save model
fold: 6/6 epoch: 103/200 train_loss: 0.070160 valid_loss: 0.091131
fold: 6/6 epoch: 104/200 train_loss: 0.070449 valid_loss: 0.086715
fold: 6/6 epoch: 105/200 train_loss: 0.070219 valid_loss: 0.084391
save model
fold: 6/6 epoch: 106/200 train_loss: 0.067623 valid_loss: 0.084248
save model
fold: 6/6 epoch: 107/200 train_loss: 0.068387 valid_loss: 0.085543
fold: 6/6 epoch: 108/200 train_loss: 0.069276 valid_loss: 0.086600
fold: 6/6 epoch: 109/200 train_loss: 0.067227 valid_loss: 0.086632
fold: 6/6 epoch: 110/200 train_loss: 0.067477 valid_loss: 0.089782
fold: 6/6 epoch: 111/200 train_loss: 0.066362 valid_loss: 0.088052
fold: 6/6 epoch: 112/200 train_loss: 0.064714 valid_loss: 0.085709
fold: 6/6 epoch: 113/200 train_loss: 0.064980 valid_loss: 0.083780
save model
fold: 6/6 epoch: 114/200 train_loss: 0.065773 valid_loss: 0.088233
fold: 6/6 epoch: 115/200 train_loss: 0.065118 valid_loss: 0.084179
fold: 6/6 epoch: 116/200 train_loss: 0.063718 valid_loss: 0.085996
fold: 6/6 epoch: 117/200 train_loss: 0.062463 valid_loss: 0.084668
fold: 6/6 epoch: 118/200 train_loss: 0.061920 valid_loss: 0.085184
fold: 6/6 epoch: 119/200 train_loss: 0.063238 valid_loss: 0.097084
fold: 6/6 epoch: 120/200 train_loss: 0.062240 valid_loss: 0.088248
Early stopping
fold5, graph ploted
test data loss:0.05750796850770712, test r2 score:
